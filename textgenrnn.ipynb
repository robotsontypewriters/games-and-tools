{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textgenrnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotsontypewriters/games-and-tools/blob/master/textgenrnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "105H1KnT5HgZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Welcome to the Robots on Typewriters Colaboratory! Think of this as Google Docs but for coding. I'll walk you through using RoT datasets to train a textgenrnn neural net to make some fun outputs! For more about texgenrnn check out Max Woolf's fabulous documentation at \n",
        "\n",
        "To use RoT datasets, check out our github repository at https://github.com/robotsontypewriters/datasets. If you have a dataset you'd like to use that's hosted online somewhere, you should be able to use it the same way as I demonstrate below. If you have a dataset you want to put in our repository, send it to justin@batcamp.org! \n",
        "\n",
        "Don't worry about playing around and figuring things out, you can always undo things if you mess up or Justin can always revert to previous versions of this document. If you want some help using this, send Justin a message!\n",
        "\n",
        "The first chunk of code is below. The first line installs textgenrnn and the second line lets you get files fom websites. These two lines always need to run the first time you open this notebook. If you refresh or get reconnected, you will need to run those again too. \n",
        "\n",
        "The lines after that make textgen objects. You can chage the names to be more descriptive than \"textgen\" or \"textgen2\" if you want. Make as many textgent objects as you want - if you want one network to output movies and another to output actors, make 2 objects. If you only need one or if you need 5, thats also fine.\n",
        "\n",
        "To run a chunk of code, press Ctrl+Enter on Windows, Cmd+Enter on Mac, or click the little play button to the left of a code chunk. I put code in different chunks so one typo doesn't make the whole code fail to run, it only stops a little chunk.\n"
      ]
    },
    {
      "metadata": {
        "id": "Nrs_KryaCmen",
        "colab_type": "code",
        "outputId": "68baf57e-060d-4405-f39e-aaa214e12ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from textgenrnn import textgenrnn\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "textgen = textgenrnn()\n",
        "textgen2 = textgenrnn()\n",
        "textgen.reset()\n",
        "textgen2.reset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method textgenrnn.reset of <textgenrnn.textgenrnn.textgenrnn object at 0x7f587e7200f0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "D1Nu7bMD7gn4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To train a textgen object, first get your dataset and name it. for example, I had the line\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# balderdash = get_file('balderdash.txt', origin= \"https://raw.githubusercontent.com/robotsontypewriters/datasets/master/balderdash.txt\")\n",
        "```\n",
        "\n",
        "in my code. I start with the name for my dataset, balderdash, then I tell the notebook where to get the data. After the equals sign, I put, in quotes, the name of the file then a comma, then the url for the file in quotes. If you're using the RoT github, you can use leave everytihng the same except the word \"balderdash\" and replace it with the desired dataset. Alternatively, you can find the link you need by clicking into one of the files in our repository, clicking RAW, and copying the link to that page.\n",
        "\n",
        "\n",
        "```\n",
        "textgen.train_from_file(balderdash, num_epochs=10, gen_epochs=5)\n",
        "```\n",
        "\n",
        "\n",
        "The last line is telling the textgen object that I named textgen to train from the file I named balderdash. In this case, I wanted it to train for 10 epochs and I wanted it to generate some content for me to see after every 5 epochs of training. Think of an epoch as a single loop through the dataset. Bigger datasets = longer epochs. You can adjust those numbers until you get outputs you like. As a general rule, if your text is nonsensical and the loss value is much bigger than 1,  you might want to train for a few more epochs. If the text is repetitive and the loss value is smaller than 1, you might have overfit on your training data and you should reset the model. You can always run the \n",
        "\n",
        "\n",
        "```\n",
        "textgen.reset()\n",
        "```\n",
        "function to clear a model's memory and reset it for training. Remember, if you don't do that, training is cumulative. So if you run 5 epochs of training then run that same chunk again, you just ran 10 epochs of training!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "exyUyjVNCmey",
        "colab_type": "code",
        "outputId": "b8b1ccd3-713b-42a2-b531-965290c48e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1580
        }
      },
      "cell_type": "code",
      "source": [
        "balderdash = get_file('balderdash.txt', origin= \"https://raw.githubusercontent.com/robotsontypewriters/datasets/master/balderdash.txt\")\n",
        "\n",
        "textgen.train_from_file(balderdash, num_epochs=10, gen_epochs=5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/robotsontypewriters/datasets/master/balderdash.txt\n",
            "\r8192/3456 [=======================================================================] - 0s 0us/step\n",
            "331 texts collected.\n",
            "Training on 3,113 character sequences.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/10\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 3.2852\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 2.5076\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 2.0814\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 1.7809\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 1.5806\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "sophia\n",
            "\n",
            "scheelock\n",
            "\n",
            "scheelka\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "wizzundoman\n",
            "\n",
            "singling\n",
            "\n",
            "schleld\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "coogo\n",
            "\n",
            "bejatvoctanzie\n",
            "\n",
            "forning\n",
            "\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 1.4201\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 1.3027\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 1.2188\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 1.1598\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 1.1082\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "scheelic\n",
            "\n",
            "scrolling\n",
            "\n",
            "scarpophilit\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "betwerexe\n",
            "\n",
            "scarpopia\n",
            "\n",
            "scomotoo\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "begilycola\n",
            "\n",
            "zbzzersk\n",
            "\n",
            "fetpopup\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NF2SzkmK-SBG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below, I do the same thing again but I train a different object on a different dataset. What I do to textgen2 has no impact on textgen and vice versa."
      ]
    },
    {
      "metadata": {
        "id": "PMbDoa8jCme6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mst = get_file('mst3k.txt', origin= \"https://raw.githubusercontent.com/robotsontypewriters/datasets/master/mst3k.txt\")\n",
        "\n",
        "textgen2.train_from_file(mst, num_epochs=5, gen_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHqq-oA_-kPV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that my models are trained, I can make them generate stuff! I like to specify a number of generations and a temperature, but see Max Woolf's documentation to see what else you can specify. I use the line \n",
        "\n",
        "```\n",
        "textgen2.generate(n= 20, temperature=0.8)\n",
        "```\n",
        "to tell textgen2 to give me 20 outputs at temperature 0.8. Temperature is a measure or randomness between 0 and 1. If the outputs are too samey, turn up the temperature! If they are too wild and incomprehensible, turn it down! If Your outputs from the training step should give you a hint as to what temperature is going to suit your model best.\n"
      ]
    },
    {
      "metadata": {
        "id": "u5czQxERCmfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "textgen2.generate(n= 20, temperature=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gInypxD_ZXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The outputs from the last time code was ran will stick around when someone opens a colaboratory, but there isn't support for me to view your outputs in real time or vice versa. When we open a colaborartory, we can change inputs together but our outputs are unique to our own runtimes. If you want to share outputs with a friend, save them (either as a file - see textgenrnn documentation - or as screenshots). Not that this place is gonna be super busy, but try to respect other people's experience here by not editing code while others are using it - just copy or add stuff down below! You can change anything you want, but it would be great if these comments can stay to guide future textgenners! If RoT uses other fun Python tools like this, I'll make Colaboratorys for those too! "
      ]
    },
    {
      "metadata": {
        "id": "9Jq_xGyVCmfH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "textgen.generate(n=20, temperature=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}